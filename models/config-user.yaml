TheBloke_guanaco-65B-GPTQ$:
  loader: AutoGPTQ
  cpu_memory: 0
  auto_devices: true
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: true
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 0
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 6000
  low_vram: false
guanaco-7B.ggmlv3.q8_0.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 24
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 25
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
guanaco-13B.ggmlv3.q8_0.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 20
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
guanaco-65B.ggmlv3.q8_0.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 5
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
  low_vram: false
guanaco-65B.ggmlv3.q2_K.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 15
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
  low_vram: true
  n_gqa: 0
  rms_norm_eps: 0
guanaco-33B.ggmlv3.q8_0.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  mlock: false
  n_gpu_layers: 10
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
llama-2-13b-chat.ggmlv3.q8_0.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: true
  mlock: false
  n_gpu_layers: 15
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
llama-2-13b.ggmlv3.q8_0.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: true
  mlock: false
  n_gpu_layers: 15
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
TheBlock_Llama-2-70B-GPTQ$:
  loader: AutoGPTQ
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 5000
TheBlock_Llama-2-70B-chat-GPTQ$:
  loader: AutoGPTQ
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: '4'
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 0
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  n_gpu_layers: 0
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 6000
Wizard-Vicuna-30B-Uncensored.ggmlv3.q8_0.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  n_gpu_layers: 10
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
llama-2-70b-chat.ggmlv3.q2_K.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: true
  mlock: false
  n_gpu_layers: 15
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
  n_gqa: 8
  rms_norm_eps: 1.0e-05
Wizard-Vicuna-13B-Uncensored.ggmlv3.q8_0.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: false
  mlock: false
  n_gpu_layers: 18
  n_ctx: 4096
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
Wizard-Vicuna-30B-Uncensored.ggmlv3.q2_K.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: true
  mlock: false
  n_gpu_layers: 30
  n_ctx: 2048
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
  n_gqa: 0
  rms_norm_eps: 0
llama-2-70b.ggmlv3.q2_K.bin$:
  loader: llama.cpp
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  bf16: false
  load_in_8bit: false
  trust_remote_code: false
  load_in_4bit: false
  compute_dtype: float16
  quant_type: nf4
  use_double_quant: false
  wbits: None
  groupsize: None
  model_type: llama
  pre_layer: 0
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  threads: 16
  n_batch: 512
  no_mmap: false
  low_vram: true
  mlock: false
  n_gpu_layers: 15
  n_ctx: 2048
  n_gqa: 8
  rms_norm_eps: 1.0e-05
  llama_cpp_seed: 0.0
  gpu_split: ''
  max_seq_len: 2048
  compress_pos_emb: 1
  alpha_value: 1
  gpu_memory_0: 0
7B-Guanaco-QLoRA$:
  loader: AutoGPTQ
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  trust_remote_code: false
  wbits: '8'
  groupsize: None
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  gpu_memory_0: 6000
llama-2-7B-Guanaco-QLoRA-GPTQ$:
  loader: AutoGPTQ
  cpu_memory: 0
  auto_devices: false
  disk: false
  cpu: false
  trust_remote_code: false
  wbits: '8'
  groupsize: None
  triton: false
  desc_act: false
  no_inject_fused_attention: false
  no_inject_fused_mlp: false
  no_use_cuda_fp16: false
  gpu_memory_0: 6000
